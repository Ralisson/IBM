{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n",
    "from project_lib import Project\n",
    "project = Project(project_id='8f23d16a-bcec-44fd-b57e-089fffb149d7', project_access_token='p-98606b388205865c63e4803f5e31406948635405')\n",
    "pc = project.project_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MARATONA BEHIND THE CODE 2020\n",
    "\n",
    "## DESAFIO 6 - LIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabnet[cpu] in d:\\program_files\\anaconda3\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: tensorflow; extra == \"cpu\" in d:\\program_files\\anaconda3\\lib\\site-packages (from tabnet[cpu]) (2.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (2.10.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.11.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.31.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (3.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (2.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.14.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.4.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.18.1)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorflow; extra == \"cpu\"->tabnet[cpu]) (0.34.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.20.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.7.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (45.2.0.post20200210)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\program_files\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (3.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in d:\\program_files\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\program_files\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (0.2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program_files\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\program_files\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\program_files\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\program_files\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in d:\\program_files\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (1.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\program_files\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\program_files\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow; extra == \"cpu\"->tabnet[cpu]) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tabnet[gpu]\n",
    "!pip install tabnet[cpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ocultando mensagens de warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dos conjuntos de dados em formato .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>graduacao</th>\n",
       "      <th>universidade</th>\n",
       "      <th>profissao</th>\n",
       "      <th>organizacao</th>\n",
       "      <th>pretende_fazer_cursos_lit</th>\n",
       "      <th>interesse_mba_lit</th>\n",
       "      <th>importante_ter_certificado</th>\n",
       "      <th>horas_semanais_estudo</th>\n",
       "      <th>como_conheceu_lit</th>\n",
       "      <th>total_modulos</th>\n",
       "      <th>modulos_iniciados</th>\n",
       "      <th>modulos_finalizados</th>\n",
       "      <th>certificados</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15852</th>\n",
       "      <td>620397030.0</td>\n",
       "      <td>Bacharelado</td>\n",
       "      <td>UFF</td>\n",
       "      <td>Outros</td>\n",
       "      <td>Borracha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perfil6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15853</th>\n",
       "      <td>229931283.0</td>\n",
       "      <td>Bacharelado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advogado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Linkedin</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perfil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15854</th>\n",
       "      <td>480674907.0</td>\n",
       "      <td>Tecnólogo</td>\n",
       "      <td>UNIP</td>\n",
       "      <td>Sócio/Dono/Proprietário</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Outros</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855</th>\n",
       "      <td>559626807.0</td>\n",
       "      <td>SEM FORMAÇÃO</td>\n",
       "      <td>UNIVERSIDADE NOVE DE JULHO</td>\n",
       "      <td>Advogado</td>\n",
       "      <td>Estado</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>226.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>perfil1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>743652801.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FGV-RJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Siderurgica</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Outros</td>\n",
       "      <td>125.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>perfil1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     graduacao                universidade  \\\n",
       "15852  620397030.0   Bacharelado                         UFF   \n",
       "15853  229931283.0   Bacharelado                         NaN   \n",
       "15854  480674907.0     Tecnólogo                        UNIP   \n",
       "15855  559626807.0  SEM FORMAÇÃO  UNIVERSIDADE NOVE DE JULHO   \n",
       "15856  743652801.0           NaN                      FGV-RJ   \n",
       "\n",
       "                     profissao  organizacao  pretende_fazer_cursos_lit  \\\n",
       "15852                   Outros     Borracha                        0.0   \n",
       "15853                 Advogado          NaN                        0.0   \n",
       "15854  Sócio/Dono/Proprietário          NaN                        0.0   \n",
       "15855                 Advogado       Estado                        0.0   \n",
       "15856                      NaN  Siderurgica                        1.0   \n",
       "\n",
       "       interesse_mba_lit  importante_ter_certificado  horas_semanais_estudo  \\\n",
       "15852                0.0                         1.0                    8.0   \n",
       "15853                0.0                         1.0                    7.0   \n",
       "15854                NaN                         1.0                    7.0   \n",
       "15855                0.0                         1.0                   10.0   \n",
       "15856                1.0                         1.0                    9.0   \n",
       "\n",
       "      como_conheceu_lit  total_modulos  modulos_iniciados  \\\n",
       "15852               NaN           10.0                NaN   \n",
       "15853          Linkedin           42.0               17.0   \n",
       "15854            Outros           30.0                9.0   \n",
       "15855               NaN          226.0              102.0   \n",
       "15856            Outros          125.0               98.0   \n",
       "\n",
       "       modulos_finalizados  certificados categoria  \n",
       "15852                  NaN           NaN   perfil6  \n",
       "15853                 15.0           NaN   perfil5  \n",
       "15854                  8.0           0.0   perfil5  \n",
       "15855                 93.0           1.0   perfil1  \n",
       "15856                 97.0           1.0   perfil1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset-3/master/training_dataset.csv\n",
    "df_training_dataset = pd.read_csv('./dataset/training_dataset.csv')\n",
    "df_training_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15857 entries, 0 to 15856\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          13945 non-null  float64\n",
      " 1   graduacao                   13950 non-null  object \n",
      " 2   universidade                13920 non-null  object \n",
      " 3   profissao                   13977 non-null  object \n",
      " 4   organizacao                 13961 non-null  object \n",
      " 5   pretende_fazer_cursos_lit   13989 non-null  float64\n",
      " 6   interesse_mba_lit           14003 non-null  float64\n",
      " 7   importante_ter_certificado  13918 non-null  float64\n",
      " 8   horas_semanais_estudo       13959 non-null  float64\n",
      " 9   como_conheceu_lit           13915 non-null  object \n",
      " 10  total_modulos               13987 non-null  float64\n",
      " 11  modulos_iniciados           14044 non-null  float64\n",
      " 12  modulos_finalizados         13924 non-null  float64\n",
      " 13  certificados                13979 non-null  float64\n",
      " 14  categoria                   15857 non-null  object \n",
      "dtypes: float64(9), object(6)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_training_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            13945\n",
       "graduacao                         6\n",
       "universidade                     21\n",
       "profissao                        12\n",
       "organizacao                      11\n",
       "pretende_fazer_cursos_lit         2\n",
       "interesse_mba_lit                 2\n",
       "importante_ter_certificado        1\n",
       "horas_semanais_estudo             9\n",
       "como_conheceu_lit                 9\n",
       "total_modulos                   578\n",
       "modulos_iniciados               372\n",
       "modulos_finalizados             339\n",
       "certificados                     23\n",
       "categoria                         6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_dataset.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Detalhamento do desafio: classificação multiclasse\n",
    "\n",
    "Este é um desafio cujo objetivo de negócio é a segmentação dos usuários de uma plataforma de ensino. Para tal, podemos utilizar duas abordagens: aprendizado de máquina supervisionado (classificação) ou não-supervisionado (clustering). Neste desafio será aplicada a classificação, pois é disponível um dataset já com \"labels\", ou em outras palavras, já com exemplos de dados juntamente com a variável alvo.\n",
    "\n",
    "Na biblioteca scikit-learn temos diversos algoritmos para classificação. O participante é livre para utilizar o framework que desejar para completar esse desafio.\n",
    "\n",
    "Neste notebook será mostrado um exeplo de uso do algoritmo \"Decision Tree\" para classificar parte dos estudantes em seis diferentes perfís."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "A coluna-alvo neste desafio é a coluna ``categoria``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processando o dataset antes do treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo todas as linhas que possuem algum valor nulos em determinadas colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o método Pandas **DataFrame.dropna()** você pode remover todas as linhas nulas do dataset.\n",
    "\n",
    "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos no df_training_dataset antes da transformação DropNA: \n",
      "\n",
      "id                            1912\n",
      "graduacao                     1907\n",
      "universidade                  1937\n",
      "profissao                     1880\n",
      "organizacao                   1896\n",
      "pretende_fazer_cursos_lit     1868\n",
      "interesse_mba_lit             1854\n",
      "importante_ter_certificado    1939\n",
      "horas_semanais_estudo         1898\n",
      "como_conheceu_lit             1942\n",
      "total_modulos                 1870\n",
      "modulos_iniciados             1813\n",
      "modulos_finalizados           1933\n",
      "certificados                  1878\n",
      "categoria                        0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset antes da transformação DropNA: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função para deletar todas as linhas com valor NaN na coluna ``certificados'' e ``total_modulos'':\n",
    "df_training_dataset = df_training_dataset.dropna(axis='index', how='any', subset=['id', 'importante_ter_certificado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos no df_training_dataset após a transformação DropNA: \n",
      "\n",
      "id                               0\n",
      "graduacao                     1467\n",
      "universidade                  1507\n",
      "profissao                     1441\n",
      "organizacao                   1417\n",
      "pretende_fazer_cursos_lit     1416\n",
      "interesse_mba_lit             1418\n",
      "importante_ter_certificado       0\n",
      "horas_semanais_estudo         1474\n",
      "como_conheceu_lit             1498\n",
      "total_modulos                 1460\n",
      "modulos_iniciados             1411\n",
      "modulos_finalizados           1460\n",
      "certificados                  1434\n",
      "categoria                        0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset após a transformação DropNA: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processando valores NaN com o SimpleImputer do sklearn\n",
    "\n",
    "Para os valores NaN, usaremos a substituição pela constante 0 como **exemplo**.\n",
    "\n",
    "Você pode escolher a estratégia que achar melhor para tratar os valores nulos :)\n",
    "\n",
    "Docs: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html?highlight=simpleimputer#sklearn.impute.SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "impute_zeros = SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='constant',\n",
    "    fill_value=0,\n",
    "    verbose=0,\n",
    "    copy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos no df_training_dataset antes da transformação SimpleImputer: \n",
      "\n",
      "id                               0\n",
      "graduacao                     1467\n",
      "universidade                  1507\n",
      "profissao                     1441\n",
      "organizacao                   1417\n",
      "pretende_fazer_cursos_lit     1416\n",
      "interesse_mba_lit             1418\n",
      "importante_ter_certificado       0\n",
      "horas_semanais_estudo         1474\n",
      "como_conheceu_lit             1498\n",
      "total_modulos                 1460\n",
      "modulos_iniciados             1411\n",
      "modulos_finalizados           1460\n",
      "certificados                  1434\n",
      "categoria                        0\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos no df_training_dataset após a transformação SimpleImputer: \n",
      "\n",
      "id                            0\n",
      "graduacao                     0\n",
      "universidade                  0\n",
      "profissao                     0\n",
      "organizacao                   0\n",
      "pretende_fazer_cursos_lit     0\n",
      "interesse_mba_lit             0\n",
      "importante_ter_certificado    0\n",
      "horas_semanais_estudo         0\n",
      "como_conheceu_lit             0\n",
      "total_modulos                 0\n",
      "modulos_iniciados             0\n",
      "modulos_finalizados           0\n",
      "certificados                  0\n",
      "categoria                     0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))\n",
    "\n",
    "# Aplicando a transformação ``SimpleImputer`` no conjunto de dados base\n",
    "impute_zeros.fit(X=df_training_dataset)\n",
    "\n",
    "# Reconstruindo um Pandas DataFrame com os resultados\n",
    "df_training_dataset_imputed = pd.DataFrame.from_records(\n",
    "    data=impute_zeros.transform(\n",
    "        X=df_training_dataset\n",
    "    ),\n",
    "    columns=df_training_dataset.columns\n",
    ")\n",
    "\n",
    "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_imputed.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando colunas indesejadas\n",
    "\n",
    "Vamos **demonstrar** abaixo como usar o método **DataFrame.drop()**.\n",
    "\n",
    "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>graduacao</th>\n",
       "      <th>universidade</th>\n",
       "      <th>profissao</th>\n",
       "      <th>organizacao</th>\n",
       "      <th>pretende_fazer_cursos_lit</th>\n",
       "      <th>interesse_mba_lit</th>\n",
       "      <th>importante_ter_certificado</th>\n",
       "      <th>horas_semanais_estudo</th>\n",
       "      <th>como_conheceu_lit</th>\n",
       "      <th>total_modulos</th>\n",
       "      <th>modulos_iniciados</th>\n",
       "      <th>modulos_finalizados</th>\n",
       "      <th>certificados</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12235</th>\n",
       "      <td>620397030.0</td>\n",
       "      <td>Bacharelado</td>\n",
       "      <td>UFF</td>\n",
       "      <td>Outros</td>\n",
       "      <td>Borracha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12236</th>\n",
       "      <td>229931283.0</td>\n",
       "      <td>Bacharelado</td>\n",
       "      <td>0</td>\n",
       "      <td>Advogado</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Linkedin</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12237</th>\n",
       "      <td>480674907.0</td>\n",
       "      <td>Tecnólogo</td>\n",
       "      <td>UNIP</td>\n",
       "      <td>Sócio/Dono/Proprietário</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Outros</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12238</th>\n",
       "      <td>559626807.0</td>\n",
       "      <td>SEM FORMAÇÃO</td>\n",
       "      <td>UNIVERSIDADE NOVE DE JULHO</td>\n",
       "      <td>Advogado</td>\n",
       "      <td>Estado</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>perfil1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12239</th>\n",
       "      <td>743652801.0</td>\n",
       "      <td>0</td>\n",
       "      <td>FGV-RJ</td>\n",
       "      <td>0</td>\n",
       "      <td>Siderurgica</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Outros</td>\n",
       "      <td>125.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>perfil1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     graduacao                universidade  \\\n",
       "12235  620397030.0   Bacharelado                         UFF   \n",
       "12236  229931283.0   Bacharelado                           0   \n",
       "12237  480674907.0     Tecnólogo                        UNIP   \n",
       "12238  559626807.0  SEM FORMAÇÃO  UNIVERSIDADE NOVE DE JULHO   \n",
       "12239  743652801.0             0                      FGV-RJ   \n",
       "\n",
       "                     profissao  organizacao  pretende_fazer_cursos_lit  \\\n",
       "12235                   Outros     Borracha                        0.0   \n",
       "12236                 Advogado            0                        0.0   \n",
       "12237  Sócio/Dono/Proprietário            0                        0.0   \n",
       "12238                 Advogado       Estado                        0.0   \n",
       "12239                        0  Siderurgica                        1.0   \n",
       "\n",
       "       interesse_mba_lit  importante_ter_certificado  horas_semanais_estudo  \\\n",
       "12235                0.0                         1.0                    8.0   \n",
       "12236                0.0                         1.0                    7.0   \n",
       "12237                0.0                         1.0                    7.0   \n",
       "12238                0.0                         1.0                   10.0   \n",
       "12239                1.0                         1.0                    9.0   \n",
       "\n",
       "      como_conheceu_lit  total_modulos  modulos_iniciados  \\\n",
       "12235                 0           10.0                0.0   \n",
       "12236          Linkedin           42.0               17.0   \n",
       "12237            Outros           30.0                9.0   \n",
       "12238                 0          226.0              102.0   \n",
       "12239            Outros          125.0               98.0   \n",
       "\n",
       "       modulos_finalizados  certificados categoria  \n",
       "12235                  0.0           0.0   perfil6  \n",
       "12236                 15.0           0.0   perfil5  \n",
       "12237                  8.0           0.0   perfil5  \n",
       "12238                 93.0           1.0   perfil1  \n",
       "12239                 97.0           1.0   perfil1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_dataset_imputed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_rmcolumns = df_training_dataset_imputed.drop(columns=['id', 'importante_ter_certificado', \n",
    "                                                                          'organizacao', 'universidade'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graduacao</th>\n",
       "      <th>profissao</th>\n",
       "      <th>pretende_fazer_cursos_lit</th>\n",
       "      <th>interesse_mba_lit</th>\n",
       "      <th>horas_semanais_estudo</th>\n",
       "      <th>como_conheceu_lit</th>\n",
       "      <th>total_modulos</th>\n",
       "      <th>modulos_iniciados</th>\n",
       "      <th>modulos_finalizados</th>\n",
       "      <th>certificados</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Especialização</td>\n",
       "      <td>Analista Senior</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Google</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MBA</td>\n",
       "      <td>Supervisor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bacharelado</td>\n",
       "      <td>Outros</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Saint Paul</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEM FORMAÇÃO</td>\n",
       "      <td>Outros</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tecnólogo</td>\n",
       "      <td>SEM EXPERIÊNCIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Google</td>\n",
       "      <td>67.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        graduacao        profissao  pretende_fazer_cursos_lit  \\\n",
       "0  Especialização  Analista Senior                        1.0   \n",
       "1             MBA       Supervisor                        0.0   \n",
       "2     Bacharelado           Outros                        1.0   \n",
       "3    SEM FORMAÇÃO           Outros                        0.0   \n",
       "4       Tecnólogo  SEM EXPERIÊNCIA                        0.0   \n",
       "\n",
       "   interesse_mba_lit  horas_semanais_estudo como_conheceu_lit  total_modulos  \\\n",
       "0                1.0                    6.0            Google           28.0   \n",
       "1                0.0                    6.0                 0           66.0   \n",
       "2                1.0                   10.0        Saint Paul           27.0   \n",
       "3                1.0                    5.0         Instagram           29.0   \n",
       "4                0.0                    7.0            Google           67.0   \n",
       "\n",
       "   modulos_iniciados  modulos_finalizados  certificados categoria  \n",
       "0                5.0                  4.0           0.0   perfil6  \n",
       "1               36.0                 34.0           0.0   perfil2  \n",
       "2               27.0                 27.0           0.0   perfil2  \n",
       "3               10.0                  6.0           0.0   perfil5  \n",
       "4               49.0                 44.0           0.0   perfil2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_dataset_rmcolumns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "As colunas removidas acima são apenas para fim de exemplo, você pode usar as colunas que quiser e inclusive criar novas colunas com dados que achar importantes!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de de variáveis categóricas\n",
    "\n",
    "Como mencionado antes, os computadores não são bons com variáveis \"categóricas\" (ou strings).\n",
    "\n",
    "Dado uma coluna com variável categórica, o que podemos realizar é a codificação dessa coluna em múltiplas colunas contendo variáveis binárias. Esse processo é chamado de \"one-hot-encoding\" ou \"dummy encoding\". Se você não é familiarizado com esses termos, você pode pesquisar mais sobre isso na internet :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pretende_fazer_cursos_lit</th>\n",
       "      <th>interesse_mba_lit</th>\n",
       "      <th>horas_semanais_estudo</th>\n",
       "      <th>total_modulos</th>\n",
       "      <th>modulos_iniciados</th>\n",
       "      <th>modulos_finalizados</th>\n",
       "      <th>certificados</th>\n",
       "      <th>categoria</th>\n",
       "      <th>profissao_0</th>\n",
       "      <th>profissao_Advogado</th>\n",
       "      <th>...</th>\n",
       "      <th>como_conheceu_lit_0</th>\n",
       "      <th>como_conheceu_lit_Facebook</th>\n",
       "      <th>como_conheceu_lit_Google</th>\n",
       "      <th>como_conheceu_lit_Instagram</th>\n",
       "      <th>como_conheceu_lit_Linkedin</th>\n",
       "      <th>como_conheceu_lit_Minha empresa - benefício LITpass</th>\n",
       "      <th>como_conheceu_lit_Mídia (revista/jornal/web)</th>\n",
       "      <th>como_conheceu_lit_Outros</th>\n",
       "      <th>como_conheceu_lit_Saint Paul</th>\n",
       "      <th>como_conheceu_lit_YouTube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>perfil1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12239</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>perfil1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pretende_fazer_cursos_lit  interesse_mba_lit  horas_semanais_estudo  \\\n",
       "12235                        0.0                0.0                    8.0   \n",
       "12236                        0.0                0.0                    7.0   \n",
       "12237                        0.0                0.0                    7.0   \n",
       "12238                        0.0                0.0                   10.0   \n",
       "12239                        1.0                1.0                    9.0   \n",
       "\n",
       "       total_modulos  modulos_iniciados  modulos_finalizados  certificados  \\\n",
       "12235           10.0                0.0                  0.0           0.0   \n",
       "12236           42.0               17.0                 15.0           0.0   \n",
       "12237           30.0                9.0                  8.0           0.0   \n",
       "12238          226.0              102.0                 93.0           1.0   \n",
       "12239          125.0               98.0                 97.0           1.0   \n",
       "\n",
       "      categoria  profissao_0  profissao_Advogado  ...  como_conheceu_lit_0  \\\n",
       "12235   perfil6            0                   0  ...                    1   \n",
       "12236   perfil5            0                   1  ...                    0   \n",
       "12237   perfil5            0                   0  ...                    0   \n",
       "12238   perfil1            0                   1  ...                    1   \n",
       "12239   perfil1            1                   0  ...                    0   \n",
       "\n",
       "       como_conheceu_lit_Facebook  como_conheceu_lit_Google  \\\n",
       "12235                           0                         0   \n",
       "12236                           0                         0   \n",
       "12237                           0                         0   \n",
       "12238                           0                         0   \n",
       "12239                           0                         0   \n",
       "\n",
       "       como_conheceu_lit_Instagram  como_conheceu_lit_Linkedin  \\\n",
       "12235                            0                           0   \n",
       "12236                            0                           1   \n",
       "12237                            0                           0   \n",
       "12238                            0                           0   \n",
       "12239                            0                           0   \n",
       "\n",
       "       como_conheceu_lit_Minha empresa - benefício LITpass  \\\n",
       "12235                                                  0     \n",
       "12236                                                  0     \n",
       "12237                                                  0     \n",
       "12238                                                  0     \n",
       "12239                                                  0     \n",
       "\n",
       "       como_conheceu_lit_Mídia (revista/jornal/web)  como_conheceu_lit_Outros  \\\n",
       "12235                                             0                         0   \n",
       "12236                                             0                         0   \n",
       "12237                                             0                         1   \n",
       "12238                                             0                         0   \n",
       "12239                                             0                         1   \n",
       "\n",
       "       como_conheceu_lit_Saint Paul  como_conheceu_lit_YouTube  \n",
       "12235                             0                          0  \n",
       "12236                             0                          0  \n",
       "12237                             0                          0  \n",
       "12238                             0                          0  \n",
       "12239                             0                          0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tratando variáveis categóricas com o método Pandas ``get_dummies()''\n",
    "df_training = pd.get_dummies(df_training_dataset_rmcolumns, columns=['profissao', 'graduacao', 'como_conheceu_lit'])\n",
    "df_training.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "A coluna **categoria** deve ser mantida como uma string. Você não precisa processar/codificar a variável-alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando um classificador com base em uma árvore de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando FEATURES e definindo a variável TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pretende_fazer_cursos_lit', 'interesse_mba_lit',\n",
       "       'horas_semanais_estudo', 'total_modulos', 'modulos_iniciados',\n",
       "       'modulos_finalizados', 'certificados', 'categoria', 'profissao_0',\n",
       "       'profissao_Advogado', 'profissao_Analista', 'profissao_Analista Senior',\n",
       "       'profissao_Assessor', 'profissao_Coordenador', 'profissao_Diretor',\n",
       "       'profissao_Engenheiro', 'profissao_Gerente', 'profissao_Outros',\n",
       "       'profissao_SEM EXPERIÊNCIA', 'profissao_Supervisor',\n",
       "       'profissao_Sócio/Dono/Proprietário', 'graduacao_0',\n",
       "       'graduacao_Bacharelado', 'graduacao_Especialização',\n",
       "       'graduacao_Licenciatura', 'graduacao_MBA', 'graduacao_SEM FORMAÇÃO',\n",
       "       'graduacao_Tecnólogo', 'como_conheceu_lit_0',\n",
       "       'como_conheceu_lit_Facebook', 'como_conheceu_lit_Google',\n",
       "       'como_conheceu_lit_Instagram', 'como_conheceu_lit_Linkedin',\n",
       "       'como_conheceu_lit_Minha empresa - benefício LITpass',\n",
       "       'como_conheceu_lit_Mídia (revista/jornal/web)',\n",
       "       'como_conheceu_lit_Outros', 'como_conheceu_lit_Saint Paul',\n",
       "       'como_conheceu_lit_YouTube'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_training[\n",
    "    [\n",
    "      \n",
    "     'pretende_fazer_cursos_lit', 'interesse_mba_lit',\n",
    "       'horas_semanais_estudo', 'total_modulos', 'modulos_iniciados',\n",
    "       'modulos_finalizados', 'certificados', 'profissao_0',\n",
    "       'profissao_Advogado', 'profissao_Analista', 'profissao_Analista Senior',\n",
    "       'profissao_Assessor', 'profissao_Coordenador', 'profissao_Diretor',\n",
    "       'profissao_Engenheiro', 'profissao_Gerente', 'profissao_Outros',\n",
    "       'profissao_SEM EXPERIÊNCIA', 'profissao_Supervisor',\n",
    "       'profissao_Sócio/Dono/Proprietário', 'graduacao_0',\n",
    "       'graduacao_Bacharelado', 'graduacao_Especialização',\n",
    "       'graduacao_Licenciatura', 'graduacao_MBA', 'graduacao_SEM FORMAÇÃO',\n",
    "       'graduacao_Tecnólogo', 'como_conheceu_lit_0',\n",
    "       'como_conheceu_lit_Facebook', 'como_conheceu_lit_Google',\n",
    "       'como_conheceu_lit_Instagram', 'como_conheceu_lit_Linkedin',\n",
    "       'como_conheceu_lit_Minha empresa - benefício LITpass',\n",
    "       'como_conheceu_lit_Mídia (revista/jornal/web)',\n",
    "       'como_conheceu_lit_Outros', 'como_conheceu_lit_Saint Paul',\n",
    "       'como_conheceu_lit_YouTube'\n",
    "    ]\n",
    "]\n",
    "target = df_training['categoria']  ## NÃO TROQUE O NOME DA VARIÁVEL TARGET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo nosso conjunto de dados em conjuntos de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=133)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TabNet]: 32 features will be used for decision steps.\n",
      "RanF: 0.808088 (0.019969)\n",
      "GBoost: 0.809886 (0.020696)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<tabnet.tabnet.TabNetClassifier object at 0x0000014A122E95C8>' (type <class 'tabnet.tabnet.TabNetClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    796\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m                 \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-85884c9d1359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodelos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mresultados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mnomes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    407\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 248\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    806\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m                 \u001b[0mislice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 248\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     80\u001b[0m                                 \u001b[1;34m\"estimator as it does not implement a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                                 \u001b[1;34m\"'get_params' method.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                                 % (repr(estimator), type(estimator)))\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<tabnet.tabnet.TabNetClassifier object at 0x0000014A122E95C8>' (type <class 'tabnet.tabnet.TabNetClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tabnet import TabNet, TabNetClassifier\n",
    "from tabnet import StackedTabNetClassifier\n",
    "\n",
    "\n",
    "# Carregando features e Target\n",
    "X = features\n",
    "Y = target\n",
    "\n",
    "# Definindo os valores para o número de folds\n",
    "num_folds = 20\n",
    "seed = 7\n",
    "\n",
    "\n",
    "# Preparando a lista de modelos\n",
    "modelos = []\n",
    "#modelos.append(('LR', LogisticRegression()))\n",
    "#modelos.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "#modelos.append(('SVM', SVC()))\n",
    "#modelos.append(('NB', GaussianNB()))\n",
    "#modelos.append(('KNN', KNeighborsClassifier()))\n",
    "\n",
    "modelos.append(('RanF', RandomForestClassifier(bootstrap=False, max_depth=30, max_features='auto',\n",
    "                        min_samples_split=10, min_weight_fraction_leaf=0,\n",
    "                        n_estimators=100, warm_start=True)))\n",
    "\n",
    "#modelos.append(('SGD', SGDClassifier()))\n",
    "#modelos.append(('ExtraTree', ExtraTreesClassifier()))\n",
    "modelos.append(('GBoost', GradientBoostingClassifier()))\n",
    "#modelos.append(('AdaBoost', AdaBoostClassifier()))\n",
    "#modelos.append(('DesTree', DecisionTreeClassifier()))\n",
    "#modelos.append(('MLP', MLPClassifier(hidden_layer_sizes=(100,200,100,200,100 ), activation='logistic', \n",
    "                                     #solver='adam', alpha=0.0001)))\n",
    "\n",
    "modelos.append(('TabN', TabNetClassifier(feature_columns = None, num_classes = 6,\n",
    "                                        feature_dim = 64, output_dim = 32, num_features = len(features),\n",
    "                                        num_decision_steps = 5, relaxation_factor = 1.5,\n",
    "                                        sparsity_coefficient = 1e-5, batch_momentum = 0.98,\n",
    "                                        virtual_batch_size = None, norm_type = 'group',\n",
    "                                        num_groups = -1)))\n",
    "\n",
    "# Avaliando cada modelo em um loop\n",
    "resultados = []\n",
    "nomes = []\n",
    "\n",
    "for nome, modelo in modelos:\n",
    "    kfold = KFold(n_splits = num_folds, random_state = seed)\n",
    "    cv_results = cross_val_score(modelo, X, Y, cv = kfold, scoring = 'accuracy')\n",
    "    resultados.append(cv_results)\n",
    "    nomes.append(nome)\n",
    "    msg = \"%s: %f (%f)\" % (nome, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "# Boxplot para comparar os algoritmos\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparação de Algoritmos de Classificação')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(resultados)\n",
    "ax.set_xticklabels(nomes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando uma árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-58-37faccdee665>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-58-37faccdee665>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    new_model . load_weights ( 'pesos' ) X_train , _ = next ( iter ( tf_dataset ))   # Supondo que gere uma tupla (x, y). modelo . prever ( x )\u001b[0m\n\u001b[1;37m                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Método para creacion de modelos basados en arbol de desición\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#dtc = GradientBoostingClassifier(max_depth=3, max_features='auto',\n",
    "                       #min_samples_split=10, min_weight_fraction_leaf=0.001,\n",
    "                       #n_estimators=200, warm_start=True).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "dtc = TabNetClassifier(feature_columns = None, num_classes = 6,\n",
    "                                        feature_dim = 64, output_dim = 32, num_features = len(features),\n",
    "                                        num_decision_steps = 5, relaxation_factor = 1.5,\n",
    "                                        sparsity_coefficient = 1e-5, batch_momentum = 0.98,\n",
    "                                        virtual_batch_size = None, norm_type = 'group',\n",
    "                                        num_groups = -1, dynamic=True)\n",
    "new_model . load_weights ( 'pesos' ) X_train , _ = next ( iter ( tf_dataset ))   # Supondo que gere uma tupla (x, y). modelo . prever ( x )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<property at 0x14a0b692138>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TabNet.feature_selection_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo previsões na amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando a qualidade do modelo através da matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['parfil1', 'perfil2', 'perfil3', 'perfil4', 'perfil5', 'perfil6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring dos dados necessários para entregar a solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como entrega da sua solução, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download da \"folha de respostas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset-3/master/to_be_scored.csv\n",
    "df_to_be_scored = pd.read_csv('to_be_scored.csv')\n",
    "df_to_be_scored.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "O dataframe ``to_be_scored`` é a sua \"folha de respostas\". Note que a coluna \"categoria\" não existe nessa amostra, que não pode ser então utilizada para treino de modelos de aprendizado supervisionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_be_scored.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Atenção!\n",
    "\n",
    "# Para poder aplicar seu modelo e classificar a folha de respostas, você precisa primeiro aplicar as mesmas transformações com colunas que você aplicou no dataset de treino.\n",
    "\n",
    "# Não remova ou adicione linhas na folha de respostas. \n",
    "\n",
    "# Não altere a ordem das linhas na folha de respostas.\n",
    "\n",
    "# Ao final, as 1000 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, repetimos rapidamente os mesmos passos de pré-processamento usados no exemplo dado com árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Removendo linhas com valores NaN em \"certificados\" e \"total_modulos\"\n",
    "df_to_be_scored_1 = df_to_be_scored.dropna(axis='index', how='any', subset=['id'])\n",
    "\n",
    "# 2 - Inputando zeros nos valores faltantes\n",
    "impute_zeros.fit(X=df_to_be_scored_1)\n",
    "df_to_be_scored_2 = pd.DataFrame.from_records(\n",
    "    data=impute_zeros.transform(\n",
    "        X=df_to_be_scored_1\n",
    "    ),\n",
    "    columns=df_to_be_scored_1.columns\n",
    ")\n",
    "\n",
    "# 3 - Remoção de colunas\n",
    "df_to_be_scored_3 = df_to_be_scored_2.drop(columns=['id', 'importante_ter_certificado','organizacao', 'universidade'], inplace=False)\n",
    "\n",
    "# 4 - Encoding com \"dummy variables\"\n",
    "df_to_be_scored_4 = pd.get_dummies(df_to_be_scored_3, columns=['profissao', 'graduacao', 'como_conheceu_lit'])\n",
    "\n",
    "df_to_be_scored_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Pode ser verificado abaixo que as colunas da folha de resposta agora são idênticas às que foram usadas para treinar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training[\n",
    "    [\n",
    "       'pretende_fazer_cursos_lit', 'interesse_mba_lit',\n",
    "       'horas_semanais_estudo', 'total_modulos', 'modulos_iniciados',\n",
    "       'modulos_finalizados', 'certificados', 'profissao_0',\n",
    "       'profissao_Advogado', 'profissao_Analista', 'profissao_Analista Senior',\n",
    "       'profissao_Assessor', 'profissao_Coordenador', 'profissao_Diretor',\n",
    "       'profissao_Engenheiro', 'profissao_Gerente', 'profissao_Outros',\n",
    "       'profissao_SEM EXPERIÊNCIA', 'profissao_Supervisor',\n",
    "       'profissao_Sócio/Dono/Proprietário', 'graduacao_0',\n",
    "       'graduacao_Bacharelado', 'graduacao_Especialização',\n",
    "       'graduacao_Licenciatura', 'graduacao_MBA', 'graduacao_SEM FORMAÇÃO',\n",
    "       'graduacao_Tecnólogo', 'como_conheceu_lit_0',\n",
    "       'como_conheceu_lit_Facebook', 'como_conheceu_lit_Google',\n",
    "       'como_conheceu_lit_Instagram', 'como_conheceu_lit_Linkedin',\n",
    "       'como_conheceu_lit_Minha empresa - benefício LITpass',\n",
    "       'como_conheceu_lit_Mídia (revista/jornal/web)',\n",
    "       'como_conheceu_lit_Outros', 'como_conheceu_lit_Saint Paul',\n",
    "       'como_conheceu_lit_YouTube'\n",
    "        \n",
    "    ]\n",
    "].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_be_scored_4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção\n",
    "\n",
    "Para todas colunas que não existirem no \"df_to_be_scored\", você pode usar a técnica abaixo para adicioná-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_be_scored_4['como_conheceu_lit_0'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(df_to_be_scored_4)\n",
    "df_to_be_scored_4['target'] = y_pred\n",
    "df_to_be_scored_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando a folha de respostas como um arquivo .csv para ser submetido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project.save_data(file_name=\"results.csv\", data=df_to_be_scored_4.to_csv(index=False))\n",
    "\n",
    "data=df_to_be_scored_4.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção\n",
    "\n",
    "# A execução da célula acima irá criar um novo \"data asset\" no seu projeto no Watson Studio. Você precisará realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submissão. (os arquivos devem estar nomeados desta forma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Parabéns!\n",
    "\n",
    "Se você já está satisfeito com a sua solução, vá até a página abaixo e envie os arquivos necessários para submissão.\n",
    "\n",
    "# https://lit.maratona.dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
