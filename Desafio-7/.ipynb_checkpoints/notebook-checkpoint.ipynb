{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n",
    "from project_lib import Project\n",
    "project = Project(project_id='8a1c4c9d-7b72-403a-819b-009104be5bcd', project_access_token='p-33a9fd738b694f965a83bfaa239d9eb4ec4e6570')\n",
    "pc = project.project_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira seu project token aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MARATONA BEHIND THE CODE 2020\n",
    "\n",
    "## DESAFIO 7 - TNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in d:\\program_files\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in d:\\program_files\\anaconda3\\lib\\site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in d:\\program_files\\anaconda3\\lib\\site-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in d:\\program_files\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: xgboost in d:\\program_files\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in d:\\program_files\\anaconda3\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in d:\\program_files\\anaconda3\\lib\\site-packages (from xgboost) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imblearn in d:\\program_files\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: imbalanced-learn in d:\\program_files\\anaconda3\\lib\\site-packages (from imblearn) (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in d:\\program_files\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in d:\\program_files\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in d:\\program_files\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in d:\\program_files\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in d:\\program_files\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ocultando mensagens de warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dos conjuntos de dados em formato .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-4-14</th>\n",
       "      <th>Fradique Coutinho</th>\n",
       "      <th>-23.5661</th>\n",
       "      <th>-46.6841</th>\n",
       "      <th>34448</th>\n",
       "      <th>18</th>\n",
       "      <th>65</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>27</th>\n",
       "      <th>18.1</th>\n",
       "      <th>19</th>\n",
       "      <th>NORMAL</th>\n",
       "      <th>10184</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93176</th>\n",
       "      <td>2019-6-28</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>127878</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93177</th>\n",
       "      <td>2019-7-15</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>126558</td>\n",
       "      <td>86</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93178</th>\n",
       "      <td>2019-7-17</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>126902</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93179</th>\n",
       "      <td>2019-2-30</td>\n",
       "      <td>Faria Lima</td>\n",
       "      <td>-23.5675</td>\n",
       "      <td>-46.6929</td>\n",
       "      <td>53455</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>REABASTECER</td>\n",
       "      <td>8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93180</th>\n",
       "      <td>2019-7-20</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>124823</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2018-4-14 Fradique Coutinho  -23.5661  -46.6841   34448  18  65   6  \\\n",
       "93176  2019-6-28               Luz  -23.5365  -46.6332  127878  77  12  55   \n",
       "93177  2019-7-15               Luz  -23.5365  -46.6332  126558  86  35  11   \n",
       "93178  2019-7-17               Luz  -23.5365  -46.6332  126902  66  24  65   \n",
       "93179  2019-2-30        Faria Lima  -23.5675  -46.6929   53455  19  56  11   \n",
       "93180  2019-7-20               Luz  -23.5365  -46.6332  124823  38  10  42   \n",
       "\n",
       "       10  15  27  18.1  19       NORMAL  10184  \n",
       "93176  40   6  16    31  14       NORMAL  11338  \n",
       "93177  32  19   8     3  25       NORMAL  11355  \n",
       "93178  22  11  43    41  17       NORMAL  11357  \n",
       "93179  21   7   5    24   5  REABASTECER   8340  \n",
       "93180  11  43  36    25   6       NORMAL  11360  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_1 = pd.read_csv('data/captura.csv')\n",
    "df_data_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Estação</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>Movimentação</th>\n",
       "      <th>Original_473</th>\n",
       "      <th>Original_269</th>\n",
       "      <th>Zero</th>\n",
       "      <th>Maçã-Verde</th>\n",
       "      <th>Tangerina</th>\n",
       "      <th>Citrus</th>\n",
       "      <th>Açaí-Guaraná</th>\n",
       "      <th>Pêssego</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93176</th>\n",
       "      <td>2019-6-28</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>127878</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93177</th>\n",
       "      <td>2019-7-15</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>126558</td>\n",
       "      <td>86</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93178</th>\n",
       "      <td>2019-7-17</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>126902</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93179</th>\n",
       "      <td>2019-2-30</td>\n",
       "      <td>Faria Lima</td>\n",
       "      <td>-23.5675</td>\n",
       "      <td>-46.6929</td>\n",
       "      <td>53455</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>REABASTECER</td>\n",
       "      <td>8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93180</th>\n",
       "      <td>2019-7-20</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>124823</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tempo     Estação      LAT     LONG  Movimentação  Original_473  \\\n",
       "93176  2019-6-28         Luz -23.5365 -46.6332        127878            77   \n",
       "93177  2019-7-15         Luz -23.5365 -46.6332        126558            86   \n",
       "93178  2019-7-17         Luz -23.5365 -46.6332        126902            66   \n",
       "93179  2019-2-30  Faria Lima -23.5675 -46.6929         53455            19   \n",
       "93180  2019-7-20         Luz -23.5365 -46.6332        124823            38   \n",
       "\n",
       "       Original_269  Zero  Maçã-Verde  Tangerina  Citrus  Açaí-Guaraná  \\\n",
       "93176            12    55          40          6      16            31   \n",
       "93177            35    11          32         19       8             3   \n",
       "93178            24    65          22         11      43            41   \n",
       "93179            56    11          21          7       5            24   \n",
       "93180            10    42          11         43      36            25   \n",
       "\n",
       "       Pêssego       TARGET    row  \n",
       "93176       14       NORMAL  11338  \n",
       "93177       25       NORMAL  11355  \n",
       "93178       17       NORMAL  11357  \n",
       "93179        5  REABASTECER   8340  \n",
       "93180        6       NORMAL  11360  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_1.columns = (['Tempo', 'Estação', 'LAT', 'LONG', 'Movimentação','Original_473', \n",
    "                                                        'Original_269', 'Zero','Maçã-Verde', 'Tangerina' , 'Citrus', \n",
    "                                                        'Açaí-Guaraná', 'Pêssego',  'TARGET', 'row'])\n",
    "df_data_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Estação</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>Movimentação</th>\n",
       "      <th>Original_473</th>\n",
       "      <th>Original_269</th>\n",
       "      <th>Zero</th>\n",
       "      <th>Maçã-Verde</th>\n",
       "      <th>Tangerina</th>\n",
       "      <th>Citrus</th>\n",
       "      <th>Açaí-Guaraná</th>\n",
       "      <th>Pêssego</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93176</th>\n",
       "      <td>2019-6-28</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>127878</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93177</th>\n",
       "      <td>2019-7-15</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>126558</td>\n",
       "      <td>86</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93178</th>\n",
       "      <td>2019-7-17</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>126902</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93179</th>\n",
       "      <td>2019-2-30</td>\n",
       "      <td>Faria Lima</td>\n",
       "      <td>-23.5675</td>\n",
       "      <td>-46.6929</td>\n",
       "      <td>53455</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>REABASTECER</td>\n",
       "      <td>8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93180</th>\n",
       "      <td>2019-7-20</td>\n",
       "      <td>Luz</td>\n",
       "      <td>-23.5365</td>\n",
       "      <td>-46.6332</td>\n",
       "      <td>124823</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tempo     Estação      LAT     LONG  Movimentação  Original_473  \\\n",
       "93176  2019-6-28         Luz -23.5365 -46.6332        127878            77   \n",
       "93177  2019-7-15         Luz -23.5365 -46.6332        126558            86   \n",
       "93178  2019-7-17         Luz -23.5365 -46.6332        126902            66   \n",
       "93179  2019-2-30  Faria Lima -23.5675 -46.6929         53455            19   \n",
       "93180  2019-7-20         Luz -23.5365 -46.6332        124823            38   \n",
       "\n",
       "       Original_269  Zero  Maçã-Verde  Tangerina  Citrus  Açaí-Guaraná  \\\n",
       "93176            12    55          40          6      16            31   \n",
       "93177            35    11          32         19       8             3   \n",
       "93178            24    65          22         11      43            41   \n",
       "93179            56    11          21          7       5            24   \n",
       "93180            10    42          11         43      36            25   \n",
       "\n",
       "       Pêssego       TARGET    row  \n",
       "93176       14       NORMAL  11338  \n",
       "93177       25       NORMAL  11355  \n",
       "93178       17       NORMAL  11357  \n",
       "93179        5  REABASTECER   8340  \n",
       "93180        6       NORMAL  11360  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_dataset = df_data_1\n",
    "df_training_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93181 entries, 0 to 93180\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Tempo         93181 non-null  object \n",
      " 1   Estação       93181 non-null  object \n",
      " 2   LAT           93181 non-null  float64\n",
      " 3   LONG          93181 non-null  float64\n",
      " 4   Movimentação  93181 non-null  int64  \n",
      " 5   Original_473  93181 non-null  int64  \n",
      " 6   Original_269  93181 non-null  int64  \n",
      " 7   Zero          93181 non-null  int64  \n",
      " 8   Maçã-Verde    93181 non-null  int64  \n",
      " 9   Tangerina     93181 non-null  int64  \n",
      " 10  Citrus        93181 non-null  int64  \n",
      " 11  Açaí-Guaraná  93181 non-null  int64  \n",
      " 12  Pêssego       93181 non-null  int64  \n",
      " 13  TARGET        93181 non-null  object \n",
      " 14  row           93181 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(3)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_training_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tempo             720\n",
       "Estação            25\n",
       "LAT                25\n",
       "LONG               25\n",
       "Movimentação    14827\n",
       "Original_473       81\n",
       "Original_269       65\n",
       "Zero               63\n",
       "Maçã-Verde         43\n",
       "Tangerina          42\n",
       "Citrus             43\n",
       "Açaí-Guaraná       42\n",
       "Pêssego            42\n",
       "TARGET              2\n",
       "row             16957\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Detalhamento do desafio: classificação binária\n",
    "\n",
    "Este é um desafio cujo objetivo de negócio é a segmentação dos usuários de aplicativo de um banco. Para tal, podemos utilizar duas abordagens: aprendizado de máquina supervisionado (classificação) ou não-supervisionado (clustering). Neste desafio será aplicada a classificação, pois é disponível um dataset já com \"labels\", ou em outras palavras, já com exemplos de dados juntamente com a variável alvo.\n",
    "\n",
    "Na biblioteca scikit-learn temos diversos algoritmos para classificação. O participante é livre para utilizar o framework que desejar para completar esse desafio.\n",
    "\n",
    "Neste notebook será mostrado um exeplo de uso do algoritmo \"Decision Tree\" para classificar parte dos estudantes em seis diferentes perfís."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "A coluna-alvo neste desafio é a coluna ``TARGET``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processando o dataset antes do treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processando valores NaN com o SimpleImputer do sklearn\n",
    "\n",
    "Para os valores NaN, usaremos a substituição pela constante 0 como **exemplo**.\n",
    "\n",
    "Você pode escolher a estratégia que achar melhor para tratar os valores nulos :)\n",
    "\n",
    "Docs: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html?highlight=simpleimputer#sklearn.impute.SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "impute_zeros = SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='most_frequent',\n",
    "    fill_value=0,\n",
    "    verbose=0,\n",
    "    copy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))\n",
    "\n",
    "# Aplicando a transformação ``SimpleImputer`` no conjunto de dados base\n",
    "impute_zeros.fit(X=df_training_dataset)\n",
    "\n",
    "# Reconstruindo um Pandas DataFrame com os resultados\n",
    "df_training_dataset_imputed = pd.DataFrame.from_records(\n",
    "    data=impute_zeros.transform(\n",
    "        X=df_training_dataset\n",
    "    ),\n",
    "    columns=df_training_dataset.columns\n",
    ")\n",
    "\n",
    "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_imputed.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando colunas indesejadas\n",
    "\n",
    "Vamos **demonstrar** abaixo como usar o método **DataFrame.drop()**.\n",
    "\n",
    "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_imputed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_rmcolumns = df_training_dataset_imputed.drop(columns=[ 'Tempo', 'LAT', 'LONG', 'Movimentação', 'Estação', 'row'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_rmcolumns.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "As colunas removidas acima são apenas para fim de exemplo, você pode usar as colunas que quiser e inclusive criar novas colunas com dados que achar importantes!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de de variáveis categóricas\n",
    "\n",
    "Como mencionado antes, os computadores não são bons com variáveis \"categóricas\" (ou strings).\n",
    "\n",
    "Dado uma coluna com variável categórica, o que podemos realizar é a codificação dessa coluna em múltiplas colunas contendo variáveis binárias. Esse processo é chamado de \"one-hot-encoding\" ou \"dummy encoding\". Se você não é familiarizado com esses termos, você pode pesquisar mais sobre isso na internet :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando variáveis categóricas com o método Pandas ``get_dummies()''\n",
    "#df_training = pd.get_dummies(df_training_dataset_rmcolumns, columns=['Estação'])\n",
    "df_training = df_training_dataset_rmcolumns\n",
    "df_training.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "A coluna **TARGET** deve ser mantida como uma string. Você não precisa processar/codificar a variável-alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando um classificador com base em uma árvore de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando FEATURES e definindo a variável TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_training[\n",
    "    [\n",
    "        \n",
    "    'Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina',\n",
    "       'Citrus', 'Açaí-Guaraná', 'Pêssego'\n",
    "    ]\n",
    "    \n",
    "]\n",
    "target = df_training['TARGET']  ## NÃO TROQUE O NOME DA VARIÁVEL TARGET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo nosso conjunto de dados em conjuntos de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=133)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos módulos\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Carregando features e Target\n",
    "X = features\n",
    "Y = target\n",
    "\n",
    "# Definindo os valores para o número de folds\n",
    "num_folds = 5\n",
    "seed = 7\n",
    "\n",
    "\n",
    "# Preparando a lista de modelos\n",
    "modelos = []\n",
    "#modelos.append(('LR', LogisticRegression()))\n",
    "#modelos.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "#modelos.append(('SVM', SVC()))\n",
    "#modelos.append(('NB', GaussianNB()))\n",
    "#modelos.append(('KNN', KNeighborsClassifier()))\n",
    "\n",
    "modelos.append(('RanF', RandomForestClassifier(bootstrap=False, max_depth=30, max_features='log2',\n",
    "                        min_samples_split=10, min_weight_fraction_leaf=0,\n",
    "                        n_estimators=50, warm_start=True)))\n",
    "\n",
    "#modelos.append(('SGD', SGDClassifier()))\n",
    "#modelos.append(('ExtraTree', ExtraTreesClassifier()))\n",
    "#modelos.append(('GBoost', GradientBoostingClassifier()))\n",
    "#modelos.append(('AdaBoost', AdaBoostClassifier()))\n",
    "#modelos.append(('DesTree', DecisionTreeClassifier()))\n",
    "modelos.append(('MLP', MLPClassifier(hidden_layer_sizes=(50,50 ), activation='logistic', solver='adam', alpha=0.0001)))\n",
    "\n",
    "# Avaliando cada modelo em um loop\n",
    "resultados = []\n",
    "nomes = []\n",
    "\n",
    "for nome, modelo in modelos:\n",
    "    kfold = KFold(n_splits = num_folds, random_state = seed)\n",
    "    cv_results = cross_val_score(modelo, X, Y, cv = kfold, scoring = 'accuracy')\n",
    "    resultados.append(cv_results)\n",
    "    nomes.append(nome)\n",
    "    msg = \"%s: %f (%f)\" % (nome, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "# Boxplot para comparar os algoritmos\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparação de Algoritmos de Classificação')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(resultados)\n",
    "ax.set_xticklabels(nomes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo os melhores parâmetros do modelo acima selecionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos módulos\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = features\n",
    "Y = target\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "valores_grid = {'n_estimators' :(2,5,7,10,50), 'criterion':('gini','entropy'), 'max_depth':(3,5,10,15,25,30),\n",
    "                'min_samples_split':(2,4,7,10), 'min_weight_fraction_leaf': (0, 0.1, 0.001,0.05, 0.5), \n",
    "                'max_features':('auto', 'sqrt', 'log2'), 'bootstrap': (True,False),   \n",
    "                'warm_start':(False, True), }\n",
    "seed = 7\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = RandomForestClassifier()\n",
    "iterations = 200\n",
    "rsearch = MLPClassifier(hidden_layer_sizes=(50,50 ), activation='logistic', solver='adam', alpha=0.0001)))\n",
    "rsearch.fit(X, Y)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Melhores Parâmetros do Modelo:\\n\", rsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando um modelo de aprendizado supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para criar ensemble com Gradiente boosting Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "dtc = MLPClassifier(hidden_layer_sizes=(100,200,300,200,100),activation='relu', solver='adam',\n",
    "                    alpha=0.0001, max_iter=500).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#dtc = RandomForestClassifier(bootstrap=False, max_depth=30, max_features='log2',\n",
    "                       #min_samples_split=10, min_weight_fraction_leaf=0,\n",
    "                       #n_estimators=50, warm_start=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo previsões na amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando a qualidade do modelo através da matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['NORMAL', 'REABASTECER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring dos dados necessários para entregar a solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como entrega da sua solução, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download da \"folha de respostas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!wget --no-check-certificate --content-disposition https://gitlab.com/JoaoPedroPP/datasets/-/raw/master/ntn/to_be_scored.csv\n",
    "df_to_be_scored = pd.read_csv('./data/to_be_scored.csv')\n",
    "df_to_be_scored.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "O dataframe ``to_be_scored`` é a sua \"folha de respostas\". Note que a coluna \"TARGET\" não existe nessa amostra, que não pode ser então utilizada para treino de modelos de aprendizado supervisionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_be_scored.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Atenção!\n",
    "\n",
    "# Para poder aplicar seu modelo e classificar a folha de respostas, você precisa primeiro aplicar as mesmas transformações com colunas que você aplicou no dataset de treino.\n",
    "\n",
    "# Não remova ou adicione linhas na folha de respostas. \n",
    "\n",
    "# Não altere a ordem das linhas na folha de respostas.\n",
    "\n",
    "# Ao final, as 1000 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, repetimos rapidamente os mesmos passos de pré-processamento usados no exemplo dado com árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Removendo linhas com valores NaN\n",
    "df_to_be_scored_1 = df_to_be_scored.dropna(axis='index', how='any', subset=['Tempo', 'Estação', 'LAT', 'LONG', 'Movimentação', 'Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina', 'Citrus', 'Açaí-Guaraná', 'Pêssego'])\n",
    "\n",
    "# 2 - Inputando zeros nos valores faltantes\n",
    "impute_zeros.fit(X=df_to_be_scored_1)\n",
    "df_to_be_scored_2 = pd.DataFrame.from_records(\n",
    "    data=impute_zeros.transform(\n",
    "        X=df_to_be_scored_1\n",
    "    ),\n",
    "    columns=df_to_be_scored_1.columns\n",
    ")\n",
    "\n",
    "# 3 - Remoção de colunas\n",
    "df_to_be_scored_3 = df_to_be_scored_2.drop(columns=['Tempo', 'LAT', 'LONG', 'Movimentação', 'Estação'], inplace=False)\n",
    "\n",
    "# 4 - Encoding com \"dummy variables\" (se necessário)\n",
    "# df_to_be_scored_4 = pd.get_dummies(df_to_be_scored_3, columns=['Váriavel com dummy'])\n",
    "df_to_be_scored_4 = df_to_be_scored_3\n",
    "\n",
    "df_to_be_scored_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Pode ser verificado abaixo que as colunas da folha de resposta agora são idênticas às que foram usadas para treinar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training[\n",
    "    [\n",
    "         'Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina',\n",
    "       'Citrus', 'Açaí-Guaraná', 'Pêssego'\n",
    "    ]\n",
    "].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_be_scored_4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção\n",
    "\n",
    "Para todas colunas que não existirem no \"df_to_be_scored\", você pode usar a técnica abaixo para adicioná-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(df_to_be_scored_4)\n",
    "df_to_be_scored_4['TARGET'] = y_pred\n",
    "df_to_be_scored_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando a folha de respostas como um arquivo .csv para ser submetido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project.save_data(file_name=\"results.csv\", data=df_to_be_scored_4.to_csv(index=False))\n",
    "\n",
    "data=df_to_be_scored_4.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção\n",
    "\n",
    "# A execução da célula acima irá criar um novo \"data asset\" no seu projeto no Watson Studio. Você precisará realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submissão. (os arquivos devem estar nomeados desta forma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Parabéns!\n",
    "\n",
    "Se você já está satisfeito com a sua solução, vá até a página abaixo e envie os arquivos necessários para submissão.\n",
    "\n",
    "# https://tnt.maratona.dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
